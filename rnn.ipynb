{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fbff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc01417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('100_Unique_QA_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tokenization function: lowercases text, removes '?' and \"'\", and splits by space.\n",
    "def tokenize(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.replace('?',\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vocabulary dictionary with an unknown token '<UNK>'\n",
    "vocab ={'<UNK>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the vocabulary from questions and answers in a dataframe row\n",
    "def build_vocab(row):\n",
    "    \n",
    "    tokenized_ques = tokenize(row['question'])\n",
    "    tokenized_ans = tokenize(row['answer'])\n",
    "    merged_tokens = tokenized_ques + tokenized_ans\n",
    "\n",
    "    for token in merged_tokens:\n",
    "\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'capital', 'of', 'france', 'paris']\n",
      "['what', 'is', 'the', 'capital', 'of', 'germany', 'berlin']\n",
      "['who', 'wrote', 'to', 'kill', 'a', 'mockingbird', 'harper-lee']\n",
      "['what', 'is', 'the', 'largest', 'planet', 'in', 'our', 'solar', 'system', 'jupiter']\n",
      "['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius', '100']\n",
      "['who', 'painted', 'the', 'mona', 'lisa', 'leonardo-da-vinci']\n",
      "['what', 'is', 'the', 'square', 'root', 'of', '64', '8']\n",
      "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'gold', 'au']\n",
      "['which', 'year', 'did', 'world', 'war', 'ii', 'end', '1945']\n",
      "['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'world', 'nile']\n",
      "['what', 'is', 'the', 'capital', 'of', 'japan', 'tokyo']\n",
      "['who', 'developed', 'the', 'theory', 'of', 'relativity', 'albert-einstein']\n",
      "['what', 'is', 'the', 'freezing', 'point', 'of', 'water', 'in', 'fahrenheit', '32']\n",
      "['which', 'planet', 'is', 'known', 'as', 'the', 'red', 'planet', 'mars']\n",
      "['who', 'is', 'the', 'author', 'of', '1984', 'george-orwell']\n",
      "['what', 'is', 'the', 'currency', 'of', 'the', 'united', 'kingdom', 'pound']\n",
      "['what', 'is', 'the', 'capital', 'of', 'india', 'delhi']\n",
      "['who', 'discovered', 'gravity', 'newton']\n",
      "['how', 'many', 'continents', 'are', 'there', 'on', 'earth', '7']\n",
      "['which', 'gas', 'do', 'plants', 'use', 'for', 'photosynthesis', 'co2']\n",
      "['what', 'is', 'the', 'smallest', 'prime', 'number', '2']\n",
      "['who', 'invented', 'the', 'telephone', 'alexander-graham-bell']\n",
      "['what', 'is', 'the', 'capital', 'of', 'australia', 'canberra']\n",
      "['which', 'ocean', 'is', 'the', 'largest', 'pacific-ocean']\n",
      "['what', 'is', 'the', 'speed', 'of', 'light', 'in', 'vacuum', '299,792,458m/s']\n",
      "['which', 'language', 'is', 'spoken', 'in', 'brazil', 'portuguese']\n",
      "['who', 'discovered', 'penicillin', 'alexander-fleming']\n",
      "['what', 'is', 'the', 'capital', 'of', 'canada', 'ottawa']\n",
      "['what', 'is', 'the', 'largest', 'mammal', 'on', 'earth', 'whale']\n",
      "['which', 'element', 'has', 'the', 'atomic', 'number', '1', 'hydrogen']\n",
      "['what', 'is', 'the', 'tallest', 'mountain', 'in', 'the', 'world', 'everest']\n",
      "['which', 'city', 'is', 'known', 'as', 'the', 'big', 'apple', 'newyork']\n",
      "['how', 'many', 'planets', 'are', 'in', 'the', 'solar', 'system', '8']\n",
      "['who', 'painted', 'starry', 'night', 'vangogh']\n",
      "['what', 'is', 'the', 'chemical', 'formula', 'of', 'water', 'h2o']\n",
      "['what', 'is', 'the', 'capital', 'of', 'italy', 'rome']\n",
      "['which', 'country', 'is', 'famous', 'for', 'sushi', 'japan']\n",
      "['who', 'was', 'the', 'first', 'person', 'to', 'step', 'on', 'the', 'moon', 'armstrong']\n",
      "['what', 'is', 'the', 'main', 'ingredient', 'in', 'guacamole', 'avocado']\n",
      "['how', 'many', 'sides', 'does', 'a', 'hexagon', 'have', '6']\n",
      "['what', 'is', 'the', 'currency', 'of', 'china', 'yuan']\n",
      "['who', 'wrote', 'pride', 'and', 'prejudice', 'jane-austen']\n",
      "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'iron', 'fe']\n",
      "['what', 'is', 'the', 'hardest', 'natural', 'substance', 'on', 'earth', 'diamond']\n",
      "['which', 'continent', 'is', 'the', 'largest', 'by', 'area', 'asia']\n",
      "['who', 'was', 'the', 'first', 'president', 'of', 'the', 'united', 'states', 'george-washington']\n",
      "['which', 'bird', 'is', 'known', 'for', 'its', 'ability', 'to', 'mimic', 'sounds', 'parrot']\n",
      "['what', 'is', 'the', 'longest-running', 'animated', 'tv', 'show', 'simpsons']\n",
      "['what', 'is', 'the', 'smallest', 'country', 'in', 'the', 'world', 'vaticancity']\n",
      "['which', 'planet', 'has', 'the', 'most', 'moons', 'saturn']\n",
      "['who', 'wrote', 'romeo', 'and', 'juliet', 'shakespeare']\n",
      "['what', 'is', 'the', 'main', 'gas', 'in', 'earths', 'atmosphere', 'nitrogen']\n",
      "['how', 'many', 'bones', 'are', 'in', 'the', 'adult', 'human', 'body', '206']\n",
      "['which', 'metal', 'is', 'a', 'liquid', 'at', 'room', 'temperature', 'mercury']\n",
      "['what', 'is', 'the', 'capital', 'of', 'russia', 'moscow']\n",
      "['who', 'discovered', 'electricity', 'benjamin-franklin']\n",
      "['which', 'is', 'the', 'second-largest', 'country', 'by', 'land', 'area', 'canada']\n",
      "['what', 'is', 'the', 'color', 'of', 'a', 'ripe', 'banana', 'yellow']\n",
      "['which', 'month', 'has', '28', 'days', 'in', 'a', 'common', 'year', 'february']\n",
      "['what', 'is', 'the', 'study', 'of', 'living', 'organisms', 'called', 'biology']\n",
      "['which', 'country', 'is', 'home', 'to', 'the', 'great', 'wall', 'china']\n",
      "['what', 'do', 'bees', 'collect', 'from', 'flowers', 'nectar']\n",
      "['what', 'is', 'the', 'opposite', 'of', 'day', 'night']\n",
      "['what', 'is', 'the', 'capital', 'of', 'south', 'korea', 'seoul']\n",
      "['who', 'invented', 'the', 'light', 'bulb', 'edison']\n",
      "['which', 'gas', 'do', 'humans', 'breathe', 'in', 'for', 'survival', 'oxygen']\n",
      "['what', 'is', 'the', 'square', 'root', 'of', '144', '12']\n",
      "['which', 'country', 'has', 'the', 'pyramids', 'of', 'giza', 'egypt']\n",
      "['which', 'sea', 'creature', 'has', 'eight', 'arms', 'octopus']\n",
      "['which', 'holiday', 'is', 'celebrated', 'on', 'december', '25', 'christmas']\n",
      "['what', 'is', 'the', 'currency', 'of', 'japan', 'yen']\n",
      "['how', 'many', 'legs', 'does', 'a', 'spider', 'have', '8']\n",
      "['which', 'sport', 'uses', 'a', 'net,', 'ball,', 'and', 'hoop', 'basketball']\n",
      "['which', 'country', 'is', 'famous', 'for', 'its', 'kangaroos', 'australia']\n",
      "['who', 'was', 'the', 'first', 'female', 'prime', 'minister', 'of', 'the', 'uk', 'margaretthatcher']\n",
      "['which', 'is', 'the', 'fastest', 'land', 'animal', 'cheetah']\n",
      "['what', 'is', 'the', 'first', 'element', 'on', 'the', 'periodic', 'table', 'hydrogen']\n",
      "['what', 'is', 'the', 'capital', 'of', 'spain', 'madrid']\n",
      "['which', 'planet', 'is', 'the', 'closest', 'to', 'the', 'sun', 'mercury']\n",
      "['who', 'is', 'known', 'as', 'the', 'father', 'of', 'computers', 'charlesbabbage']\n",
      "['what', 'is', 'the', 'capital', 'of', 'mexico', 'mexicocity']\n",
      "['how', 'many', 'colors', 'are', 'in', 'a', 'rainbow', '7']\n",
      "['which', 'musical', 'instrument', 'has', 'black', 'and', 'white', 'keys', 'piano']\n",
      "['who', 'discovered', 'the', 'americas', 'in', '1492', 'christophercolumbus']\n",
      "['which', 'disney', 'character', 'has', 'a', 'long', 'nose', 'and', 'grows', 'it', 'when', 'lying', 'pinocchio']\n",
      "['who', 'directed', 'the', 'movie', 'titanic', 'jamescameron']\n",
      "['which', 'superhero', 'is', 'also', 'known', 'as', 'the', 'dark', 'knight', 'batman']\n",
      "['what', 'is', 'the', 'capital', 'of', 'brazil', 'brasilia']\n",
      "['which', 'fruit', 'is', 'known', 'as', 'the', 'king', 'of', 'fruits', 'mango']\n",
      "['which', 'country', 'is', 'known', 'for', 'the', 'eiffel', 'tower', 'france']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the build_vocab function to each row of the dataframe\n",
    "df.apply(build_vocab, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "321db10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b037c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a tokenized text back into a list of numerical indices\n",
    "\n",
    "def text_to_indices(text, vocab):\n",
    "\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "\n",
    "        else:\n",
    "            indexed_text.append(vocab['<UNK>'])\n",
    "\n",
    "    return indexed_text        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f01eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for handling question-answer pairs\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        numerical_ques = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
    "        numerical_ans = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
    "\n",
    "        return torch.tensor(numerical_ques), torch.tensor(numerical_ans)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d19ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN Model Definition\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim = 50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first = True)\n",
    "        self.fc = nn.Linear(64,vocab_size)\n",
    "\n",
    "    def forward(self, question):\n",
    "        embedded_ques = self.embedding(question)\n",
    "        hidden, final = self.rnn(embedded_ques)\n",
    "        output = self.fc(final).squeeze(0)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d76b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61eee475",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94221cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for question, answer in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(question)\n",
    "\n",
    "        loss = loss_fn(output, answer.squeeze(1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prediction Function ---\n",
    "def predict(model, question, threshold = 0.5):\n",
    "    #convert ques to numbers\n",
    "    numerical_ques = text_to_indices(question, vocab)\n",
    "\n",
    "    # tensor\n",
    "    ques_tensor = torch.tensor(numerical_ques).unsqueeze(0)\n",
    "\n",
    "    # send to model\n",
    "    output = model(ques_tensor)\n",
    "\n",
    "    #convert logits to probability\n",
    "    prob = torch.nn.functional.softmax(output, dim = 1)\n",
    "\n",
    "    #find index of max probability\n",
    "    value, index = torch.max(prob, dim = 1)\n",
    "\n",
    "    if value<threshold:\n",
    "        print(\"I don't know\")\n",
    "    \n",
    "    return list(vocab.keys())[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc7e559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"what is capital of germany\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
